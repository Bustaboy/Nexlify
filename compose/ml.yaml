# compose/ml.yaml
# РћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂ
# NEXLIFY ML/AI SERVICES - Neural Processing Matrix
# РћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂ
# Requires NVIDIA Container Toolkit v1.17.8+ for GPU support
# Optimized for RTX 2070 (8GB VRAM) with scaling to RTX 4090
# TimesFM, Chronos, iTransformer ensemble

services:
  # РћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂ
  # ­ЪДа ML ENGINE - Main prediction service with GPU acceleration
  # РћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂ
  ml-engine:
    image: cgr.dev/chainguard/pytorch:latest-cuda12
    container_name: nexlify-ml-engine
    profiles: ["ml", "gpu", "full"]
    build:
      context: .
      dockerfile: docker/Dockerfile.ml
      args:
        CUDA_VERSION: ${CUDA_VERSION:-12.1}
        PYTORCH_VERSION: ${PYTORCH_VERSION:-2.1.0}
      cache_from:
        - type=registry,ref=nexlify/cache:ml
      cache_to:
        - type=registry,ref=nexlify/cache:ml,mode=max
    hostname: ml-engine
    environment:
      # Core ML Configuration
      - ML_ENV=${ML_ENV:-production}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
      
      # GPU Configuration
      - CUDA_VISIBLE_DEVICES=${CUDA_DEVICES:-0}
      - CUDA_MEMORY_FRACTION=${CUDA_MEMORY_FRACTION:-0.8}
      - CUDA_LAUNCH_BLOCKING=${CUDA_LAUNCH_BLOCKING:-0}
      - TORCH_CUDA_ARCH_LIST="7.5;8.0;8.6;8.9"  # RTX 2070 to 4090
      
      # Model Configuration
      - MODEL_CACHE_DIR=/models
      - ENABLE_TIMESFM=${ENABLE_TIMESFM:-true}
      - ENABLE_CHRONOS=${ENABLE_CHRONOS:-true}
      - ENABLE_ITRANSFORMER=${ENABLE_ITRANSFORMER:-true}
      - MODEL_ENSEMBLE_WEIGHTS=${MODEL_WEIGHTS:-0.4,0.3,0.3}
      
      # Service Discovery
      - NEXLIFY_CORE_URL=http://nexlify-core:8888
      - VALKEY_HOST=valkey-cache
      - QUESTDB_HOST=questdb-ts
      
      # Performance Tuning
      - OMP_NUM_THREADS=${OMP_NUM_THREADS:-8}
      - MKL_NUM_THREADS=${MKL_NUM_THREADS:-8}
      - NUMEXPR_NUM_THREADS=${NUMEXPR_NUM_THREADS:-8}
    secrets:
      - source: ml_api_key
        target: /run/secrets/ml_api_key
        mode: 0400
    volumes:
      # Model storage with cache
      - ml-models:/models
      - ml-cache:/cache
      
      # Code mounting for development
      - ./src/ml:/app/ml:ro
      - ./config/ml:/app/config:ro
      
      # Shared memory for DataLoader
      - type: tmpfs
        target: /dev/shm
        tmpfs:
          size: 2G
    ports:
      - "${ML_API_PORT:-8891}:8891"      # REST API
      - "${ML_GRPC_PORT:-8892}:8892"     # gRPC for low latency
    healthcheck:
      test: ["CMD", "python", "-c", "import torch; assert torch.cuda.is_available(); import requests; r = requests.get('http://localhost:8891/health'); exit(0 if r.status_code == 200 else 1)"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 120s  # Models need time to load
    depends_on:
      nexlify-core:
        condition: service_healthy
    networks:
      ml-network:
        aliases:
          - ml-engine.ml
      backend:
      monitoring:
    restart: unless-stopped
    stop_grace_period: 60s  # Allow model checkpointing
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['${GPU_DEVICE_ID:-0}']  # RTX 2070 by default
              capabilities: [gpu, compute, utility]
        limits:
          cpus: '${ML_CPU_LIMIT:-4.0}'
          memory: ${ML_MEMORY_LIMIT:-8G}
        reservations:
          cpus: '2.0'
          memory: 4G
    ipc: host  # Better GPU performance
    ulimits:
      memlock:
        soft: -1
        hard: -1
      stack:
        soft: 67108864
        hard: 67108864
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
        labels: "service=ml,component=engine"

  # РћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂ
  # ­Ъћ« MODEL SERVER - TorchServe for production inference
  # РћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂ
  model-server:
    image: pytorch/torchserve:latest-gpu
    container_name: nexlify-model-server
    profiles: ["ml", "gpu", "production"]
    hostname: model-server
    environment:
      - TS_CONFIG_FILE=/config/config.properties
      - CUDA_VISIBLE_DEVICES=${CUDA_DEVICES:-0}
      - ENABLE_METRICS=true
      - METRICS_FORMAT=prometheus
    volumes:
      - ./config/torchserve:/config:ro
      - ml-models:/models
      - torchserve-logs:/logs
    ports:
      - "${TORCHSERVE_INFERENCE_PORT:-8080}:8080"   # Inference
      - "${TORCHSERVE_MANAGEMENT_PORT:-8081}:8081"  # Management
      - "${TORCHSERVE_METRICS_PORT:-8082}:8082"     # Metrics
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    networks:
      ml-network:
        aliases:
          - model-server.ml
      backend:
      monitoring:
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['${GPU_DEVICE_ID:-0}']
              capabilities: [gpu]
        limits:
          cpus: '2.0'
          memory: 6G
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=ml,component=torchserve"

  # РћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂ
  # ­ЪЊі JUPYTER LAB - ML experimentation environment (dev only)
  # РћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂ
  jupyter:
    image: cgr.dev/chainguard/jupyter:latest
    container_name: nexlify-jupyter
    profiles: ["ml", "dev"]
    hostname: jupyter
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=${JUPYTER_TOKEN:-nexlify2025}
      - CUDA_VISIBLE_DEVICES=${CUDA_DEVICES:-0}
    volumes:
      - ./notebooks:/home/jovyan/work
      - ml-models:/home/jovyan/models
      - ./src:/home/jovyan/nexlify:ro
    ports:
      - "${JUPYTER_PORT:-8893}:8888"
    networks:
      ml-network:
        aliases:
          - jupyter.ml
      backend:
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['${GPU_DEVICE_ID:-0}']
              capabilities: [gpu]
        limits:
          cpus: '2.0'
          memory: 4G
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
        labels: "service=ml,component=jupyter"

  # РћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂ
  # ­Ъј» NVIDIA DCGM EXPORTER - GPU metrics for Prometheus
  # РћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂ
  dcgm-exporter:
    image: nvidia/dcgm-exporter:3.1.7-3.1.4-ubuntu20.04
    container_name: nexlify-gpu-metrics
    profiles: ["ml", "gpu", "monitoring"]
    hostname: dcgm-exporter
    environment:
      - DCGM_EXPORTER_NO_HOSTNAME=1
      - DCGM_EXPORTER_COLLECTORS=/etc/dcgm-exporter/dcp-metrics-included.csv
    ports:
      - "${DCGM_PORT:-9400}:9400"
    cap_add:
      - SYS_ADMIN
    networks:
      monitoring:
        aliases:
          - dcgm.monitoring
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu, utility]
        limits:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=monitoring,component=dcgm"

# РћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂ
# VOLUMES - ML data persistence
# РћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂ

volumes:
  ml-models:
    name: nexlify-ml-models
    driver: local
    labels:
      com.nexlify.volume.type: "models"
      com.nexlify.volume.backup: "daily"
      com.nexlify.volume.size: "50GB"

  ml-cache:
    name: nexlify-ml-cache
    driver: local
    driver_opts:
      o: "size=20g"
    labels:
      com.nexlify.volume.type: "cache"
      com.nexlify.volume.retention: "7d"

  torchserve-logs:
    name: nexlify-torchserve-logs
    driver: local
    labels:
      com.nexlify.volume.type: "logs"
      com.nexlify.volume.retention: "14d"

# РћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂ
# SECRETS - ML service credentials
# РћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂРћЂ

secrets:
  ml_api_key:
    file: ./secrets/ml_api_key.txt
